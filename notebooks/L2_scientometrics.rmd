---
title: 'Mapping and evaluating knowledge production – Introduction to scientometrics and system mapping '
author: "Daniel S. Hain (dsh@business.aau.dk)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: true
    number_sections: yes
---

```{r setup, include=FALSE}
### Generic preamble
Sys.setenv(LANG = "en") # System language = english
options(scipen = 5) # Disable scientific exponent annotation of numbers
set.seed(1337) # Set seed for reproducability
rm(list=ls()); graphics.off() # get rid of everything in the workspace

### Load packages  
# Standard
library(knitr) # For display of the markdown
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr) # For extra-piping operators (eg. %<>%)
library(skimr) # Nice descriptives

# extra packages
library(igraph)
library(tidygraph)
library(ggraph)

### Knitr options
opts_chunk$set(warning=FALSE,
               message=FALSE,
               fig.align="center"
               )
```


## Introduction to Networks
So, before we talk about networks, one thing upfront... why should we? I mean, they undeniably look pretty, don't they?

Somehow, the visualization of networks fascinates the human mind (find a short TED talk on networks and how they depict our world [here](https://www.ted.com/talks/manuel_lima_a_visual_history_of_human_knowledge)), and has even inspired an own art movement, networkism (see some examples [here](https://www.behance.net/gallery/184045/Links)). 

Yet, besides that, is there an analytical value for a data scientist to bother about networks?

## Networks in R
There are a number of applications designed for network analysis and the creation of network graphs such as [gephi](https://gephi.org) and [cytoscape](http://cytoscape.org). Though not specifically designed for it, R has developed into a powerful tool for network analysis. 

Significant network analysis packages for R include the [`network`](https://cran.r-project.org/web/packages/network/index.html), [`sna`](https://cran.r-project.org/web/packages/sna/index.html), and [`igraph`](http://igraph.org) package. In addition, [Thomas Lin Pedersen](http://www.data-imaginist.com) has recently released the [`tidygraph`](https://cran.r-project.org/web/packages/tidygraph/index.html) package that leverage the power of `igraph` in a manner consistent with the [`tidyverse`](http://www.tidyverse.org) workflow. Even better, he tops it up with [`ggraph`](https://cran.r-project.org/web/packages/ggraph/index.html), a consistent ´ggplot2´-look-and-feel network visualization package.

R can also be used to make interactive network graphs with the [htmlwidgets framework](http://www.htmlwidgets.org) that translates R code to JavaScript. Cool implementations thereof are the [`vizNetwork`](http://datastorm-open.github.io/visNetwork/) and [`networkD3`](http://christophergandrud.github.io/networkD3/) packages. 

As analytical tool, I will in this lab mostly use [`igraph`](http://igraph.org). In terms of functions, it is pretty much equivalent to [`network`](https://cran.r-project.org/web/packages/network/index.html), yet slightly more powerful, better integrated, and maintained. Since both packages have many of the same functions, better don't load them both at once.

## The Basic Structure of Networks

### The Basic Jargon
First of all, what is a network? Plainly speaking, a network is a system of elements which are connected by some relationship. The vocabulary can be a bit technical and even inconsistent between different disciplines, packages, and software. The whole system is (surprise, surprise) usually called a **network** or **graph**. The elements are commonly referred to as **nodes** (system theory jargon) or **vertices** (graph theory jargon) of a graph, while the connections are **edges** or **links**. I will mostly refer to the elements as nodes, and their connections as edges.

Generally, networks are a form of representing **relational data**. This is a very general tool that can be applied to many different types of relationships between all kind of elements. The content, meaning, and interpretation for sure depends on what elements we display, and which types of relationships. For example:


* In Social Network Analysis:
     * Nodes represent actors (which can be persons, firms and other socially constructed entities)
     * Edges represent relationships between this actors (friendship, interaction, co-affiliation, similarity ect.)
* Other types of network
     * Chemistry: Interaction between molecules
     * Computer Science: The wirld-wide-web, inter- and intranet topologies
     * Biology: Food-web, ant-hives

The possibilities to depict relational data are manifold. For example:

* Relations among persons
     * Kinship: mother of, wife of...
     * Other role based: boss of, supervisor of...
     * Cognitive/perceptual: knows, aware of what they know...
     * Affective: likes, trusts...
     * Interaction: give advice, talks to...
     * Affiliation: belong to same clubs, shares same interests...
* Relations among organizations
     * As corporate entities
     * Buy from / sell to, leases to, outsources to
     * Owns shares of, subsidiary of
     * Joint ventures, strategic alliances
     * Via their members
          * Personnel flows
          * Interlocking directorates
          * Personal friendships
          * Co-memberships
* Relations other (non-social) entities
     * Patents
          * Patents citing other patents
          * Co-occurrence of technological classes
     *Research fields
          * through citations
          * through people co-affiliated with fields
     *Sectors
          * input-output relations
          * Labor mobility
     *Technologies
          * Patent IPC classes
          * Semantic co-occurrence 


**Note: Content matters!** Each relation yields a different structure & has different effects. Theories might make sense on inter-personal, but not inter-organizational or non-social context.


## The Data-Structure of Relational Data

### Edgelist
MOst real world relational data is to be found in what we call an **edge list**, a dataframe that contains a minimum of two columns, one column of *nodes* that are the source of a connection and another column of nodes that are the target of the connection. The nodes in the data are identified by unique IDs. If the distinction between source and target is meaningful, the network is **directed**. If the distinction is not meaningful, the network is **undirected** (more on that later). So, every row that contains the ID of one element in column 1, and the ID of another element in column 2 indicates that a connection between them exists. An edge list can also contain additional columns that describe **attributes** of the edges such as a magnitude aspect for an edge. If the edges have a magnitude attribute the graph is considered **weighted** (more on that later). Below an example ofa minimal edge list created with the `tibble()` function.

```{r edgelists}
edge_list <- tibble(from = c(1, 2, 2, 3, 4), to = c(2, 3, 4, 2, 1))
edge_list
```

Sometimes it is preferable to also create a separate node list. At its simplest, a **node list** is a data frame with a single column - which I will label as "id" - that lists the node IDs found in the edge list. The advantage of creating a separate node list is the ability to add attribute columns to the data frame such as the names of the nodes or any kind of groupings.

```{r nodelists}
node_list <- tibble(id = 1:4, group = sample(letters[1:2], 4, replace = TRUE))
node_list
```

### Adjacency Matrix

A second popular form of network representation is the **adjacency-matrix** (also called **socio-matrix**). It is represented as a $n*n$ matrix, where $n$ stands for the number of elements of which their relationships should be represented. The value in the cell that intercepts row $n$ and column $m$ indicates if an edge is present (=1) or absent (=0).

Tip: Given an edgelist, an adjacency matrix can easily be produced by crosstabulating:

```{r matrix}
adj_matrix <- table(edge_list) %>% as.matrix()
adj_matrix
```

## Generating a Graph Object in `tidygraph`

So, now it is finally time to use `tidygraph`. 


```{r}
g <- edge_list %>% as_tbl_graph(directed = FALSE)
g
```

```{r}
g %>% ggraph(layout = 'nicely') + 
  geom_edge_link() + 
  geom_node_point() + 
  geom_node_text(aes(label = name))
```



While being able to use the `dplyr` verbs on relational data is nice and all, one of the reasons we are dealing with graph data in the first place is because we need some *graph-based algorithms* for solving our problem at hand. If we need to break out of the tidy workflow every time this was needed we wouldn’t have gained much. Because of this `tidygraph` has wrapped more or less all of `igraphs` algorithms in different ways, ensuring a consistent syntax as well as output that fits into the tidy workflow. In the following we’re going to take a look at these.

Central to all of these functions is that they know about which graph is being computed on (in the same way that `n()` knows about which tibble is currently in scope). Furthermore they always return results matching the node or edge position so they can be used directly in `mutate()` calls.


## Network effects & structures

One of the simplest concepts when computing graph based values is that of centrality, i.e. how central is a node or edge in the graph. As this definition is inherently vague, a lot of different centrality scores exists that all treat the concept of central a bit different. One of the famous ones is the pagerank algorithm that was powering Google Search in the beginning. `tidygraph` currently has 11 different centrality measures and all of these are prefixed with centrality_* for easy discoverability. All of them returns a numeric vector matching the nodes (or edges in the case of `centrality_edge_betweenness()`).

```{r}
g <- play_smallworld(1, 100, 3, 0.05) %>% 
    mutate(centrality_dgr = centrality_degree(),
           centrality_eigen = centrality_eigen(),
           centrality_between = centrality_betweenness()) 
```

```{r}
g %>%
    ggraph(layout = "kk") + 
    geom_edge_link() + 
    geom_node_point(aes(size = centrality_dgr, colour = centrality_dgr)) + 
    scale_color_continuous(guide = "legend") + 
    theme_graph()
```

```{r}
g %>%
    ggraph(layout = "kk") + 
    geom_edge_link() + 
    geom_node_point(aes(size = centrality_eigen, colour = centrality_eigen)) + 
    scale_color_continuous(guide = "legend") + 
    theme_graph()
```

```{r}
g %>%
    ggraph(layout = "kk") + 
    geom_edge_link() + 
    geom_node_point(aes(size = centrality_between, colour = centrality_between)) + 
    scale_color_continuous(guide = "legend") + 
    theme_graph()
```

## Clustering (Community detection)

Another common operation is to group nodes based on the graph topology, sometimes referred to as *community detection* based on its commonality in social network analysis. All clustering algorithms from igraph is available in tidygraph using the `group_*` prefix. All of these functions return an integer vector with nodes (or edges) sharing the same integer being grouped together.

```{r}
g <- play_islands(5, 10, 0.8, 3) %N>% 
    mutate(community = as.factor(group_louvain())) 


g %>% 
    ggraph(layout = 'kk') + 
    geom_edge_link(aes(alpha = ..index..), show.legend = FALSE) + 
    geom_node_point(aes(colour = community), size = 7) + 
    theme_graph()
```

# Bibliographic mapping

## Basics

Lets talk about bibliographic networks. In short, that are networks between documents which cite each others. That can be (commonly) academic publications, but also patents or policy reports. Conceptually, we can see them as 2 mode networks, between articles and their reference. That helps us to apply some interesting metrics, such as:

* direct citations
* Bibliographic coupling
* Co--citations

Interestingly, different projections of this 2-mode network give the whole resulting 1-mode network a different meaning.

## Fun with the [`bibliometrix`](http://www.bibliometrix.org/) package

Since lately, the [`bibliometrix`](http://www.bibliometrix.org/) package became exteremly good, and by now almost suitable to replace my hand-made workflows. So, I will spare you the data munging, and demonstrate how to use the nice inbuild functionalities here. By doing so, you will develop a lot of intuition on network projection, and aggregation on different levels.

```{r}
library(bibliometrix)
```

### Loading the data

So, lets load some data. Since it is the topic of this lecture series, why not do a bibliographic mapping of "Innovation system" and "innovation ecosystem"" literature. Here I use the web of science database on scientific literature. I here downloaded the following query.

* **Data source**:   Clarivate Analytics Web of Science (http://apps.webofknowledge.com)
* **Data format**:   bibtex
* **Query**:         TOPIC: ("innovation system" OR "systems of innovation" OR "innovation ecosystem")
* **Timespan**:      the beginning of time - March 2019
* **Document Type**: Articles
* **Language**:      English
* **Query data**:    March, 2019
* **Selection**:     1000 most cited

We now just read the plain  data with the inbuild `convert2df()` function

```{r}
M <- readFiles("../input/wos_1.bib", "../input/wos_2.bib") %>%
  convert2df(dbsource = "isi",
             format = "bibtex")

M %>% head()
```


### Descriptive Analysis

Although bibliometrics is mainly known for quantifying the scientific production and measuring its quality and impact, it is also useful for displaying and analysing the intellectual, conceptual and social structures of research as well as their evolution and dynamical aspects. 

In this way, bibliometrics aims to describe how specific disciplines, scientific domains, or research fields are structured and how they evolve over time. In other words, bibliometric methods help to map the science (so-called science mapping) and are very useful in the case of research synthesis, especially for the systematic ones.

Bibliometrics is an academic science founded on a set of statistical methods, which can be used to analyze scientific big data quantitatively and their evolution over time and discover information. Network structure is often used to model the interaction among authors, papers/documents/articles, references, keywords, etc.

Bibliometrix is an open-source software for automating the stages of data-analysis and data-visualization. After converting and uploading bibliographic data in R, Bibliometrix performs a descriptive analysis and different research-structure analysis.

Descriptive analysis provides some snapshots about the annual research development, the top "k" productive authors, papers, countries and most relevant keywords.

#### Main findings about the collection

```{r}
results <- biblioAnalysis(M)
summary(results, 
        k = 20, 
        pause = F)
```

```{r}
plot(results)
```

#### Most Cited References (internally)

```{r}
CR <- citations(M, 
                field = "article", 
                sep = ";")
cbind(CR$Cited[1:10])
```

### Bibliographic Copling Analysis: The Knowledge Frontier of the Field

Bibliographic coupling is a newer technique, which has turned out to be very appropriate to capture a fields current knowledge frontier. I will show you how to do it here, but in case you are interested, read my paper :)


```{r,fig.width=15,fig.height=15}
NetMatrix <- biblioNetwork(M, 
                           analysis = "coupling", 
                           network = "references", 
                           sep = ";")

net <-networkPlot(NetMatrix, 
            n = 50, 
            Title = "Bibliographic Coupling Network", 
            type = "fruchterman", 
            size.cex = TRUE, 
            size = 20, 
            remove.multiple = FALSE, 
            labelsize = 0.7,
            edgesize = 10, 
            edges.min = 5)
```

### Co-citation Analysis: The Intellectual Structure and Knowledge Bases of the field 

Citation analysis is one of the main classic techniques in bibliometrics. It shows the structure of a specific field through the linkages between nodes (e.g. authors, papers, journal), while the edges can be differently interpretated depending on the network type, that are namely co-citation, direct citation, bibliographic coupling. 

Below there are three examples.

* First, a co-citation network that shows relations between cited-reference works (nodes).
* Second, a co-citation network that uses cited-journals as unit of analysis. The useful dimensions to comment the co-citation networks are: (i) centrality and peripherality of nodes, (ii) their proximity and distance, (iii) strength of ties, (iv) clusters, (iiv) bridging contributions.
* Third, a historiograph is built on direct citations. It draws the intellectual linkages in a historical order. Cited works of thousands of authors contained in a collection of published scientific articles is sufficient for recostructing the historiographic structure of the field, calling out the basic works in it.


#### Co-citation (cited references) analysis

**Plot options**:

* n = 50 (the funxtion plots the main 50 cited references)
* type = "fruchterman" (the network layout is generated using the Fruchterman-Reingold Algorithm)
* size.cex = TRUE (the size of the vertices is proportional to their degree)
* size = 20 (the max size of vertices)
* remove.multiple=FALSE (multiple edges are not removed)
* labelsize = 0.7 (defines the size of vertex labels)
* edgesize = 10 (The thickness of the edges is proportional to their strength. Edgesize defines the max value of the thickness)
* edges.min = 5 (plots only edges with a strength greater than or equal to 5)
* all other arguments assume the default values

```{r,fig.width=15,fig.height=15}
NetMatrix <- biblioNetwork(M, 
                           analysis = "co-citation", 
                           network = "references", 
                           sep = ";")

net <-networkPlot(NetMatrix, 
            n = 50, 
            Title = "Co-Citation Network", 
            type = "fruchterman", 
            size.cex = TRUE, 
            size = 20, 
            remove.multiple = FALSE, 
            labelsize = 0.7,
            edgesize = 10, 
            edges.min = 5)
```

#### Cited Journal (Source) co-citation analysis

```{r,fig.width=15,fig.height=15}
M <- metaTagExtraction(M, "CR_SO", sep=";")

NetMatrix <- biblioNetwork(M, 
                           analysis = "co-citation", 
                           network = "sources", 
                           sep = ";")

net <-networkPlot(NetMatrix, 
            n = 50, 
            Title = "Co-Citation Network", 
            type = "auto", 
            size.cex = TRUE, 
            size = 15, 
            remove.multiple = FALSE, 
            labelsize = 0.7,
            edgesize = 10, 
            edges.min = 5)
```

by the way, the results contain an "hidden" igraph obejct. That is new, and makes further analysis of the results possible. Great!

```{r}
str(net, max.level = 2)

net$graph
```

Some summary statistics. I will only provide them here, but theur are availabel for all object created with `biblioNetwork()`

```{r}
netstat <- networkStat(NetMatrix)
summary(netstat, k = 10)
```


#### Historiograph - Direct citation linkages

We can also look at a histograph of ciation pattern over time.

```{r,fig.width=15,fig.height=15}
histResults <- histNetwork(M, 
                           min.citations = quantile(M$TC,0.75, na.rm = TRUE), 
                           sep = ";")

net <- histPlot(histResults, 
                n = 20, 
                size.cex=TRUE, 
                size = 5, 
                labelsize = 3, 
                arrowsize = 0.5)
```



### The conceptual structure and context - Co-Word Analysis

Co-word networks show the conceptual structure, that uncovers links between concepts through term co-occurences.

Conceptual structure is often used to understand the topics covered by scholars (so-called research front) and identify what are the most important and the most recent issues.

Dividing the whole timespan in different timeslices and comparing the conceptual structures is useful to analyze the evolution of topics over time.

Bibliometrix is able to analyze keywords, but also the terms in the articles' titles and abstracts. It does it using network analysis or correspondance analysis (CA) or multiple correspondance analysis (MCA). CA and MCA visualise the conceptual structure in a two-dimensional plot.

We can even do way more fancy stuff with abstracts or full texts (and do so). However, I dont want to spoiler Romans sessions, so I will hold myself back here

#### Co-word Analysis through Keyword co-occurrences

**Plot options**:

* normalize = "association" (the vertex similarities are normalized using association strength)
* n = 50 (the function plots the main 50 cited references)
* type = "fruchterman" (the network layout is generated using the Fruchterman-Reingold Algorithm)
* size.cex = TRUE (the size of the vertices is proportional to their degree)
* size = 20 (the max size of the vertices) 
* remove.multiple=FALSE (multiple edges are not removed)
* labelsize = 3 (defines the max size of vertex labels)
* label.cex = TRUE (The vertex label sizes are proportional to their degree)
* edgesize = 10 (The thickness of the edges is proportional to their strength. Edgesize defines the max value of the thickness)
* label.n = 30 (Labels are plotted only for the main 30 vertices)
* edges.min = 25 (plots only edges with a strength greater than or equal to 2)
* all other arguments assume the default values

```{r Keyword co-occurrences, comment=NA, fig.height=15, fig.width=15}
NetMatrix <- biblioNetwork(M, 
                           analysis = "co-occurrences", 
                           network = "keywords", 
                           sep = ";")

net <- networkPlot(NetMatrix, 
                   normalize = "association", 
                   n = 50, 
                   Title = "Keyword Co-occurrences", 
                   type = "fruchterman", 
                   size.cex = TRUE, size = 20, remove.multiple = FALSE, 
                   edgesize = 10, 
                   labelsize = 3,
                   label.cex = TRUE,
                   label.n = 50,
                   edges.min = 2)
```


#### Co-word Analysis through Correspondence Analysis

You already saw that comming, right?

```{r}
CS <- conceptualStructure(M, 
                          method = "CA", 
                          field = "ID", 
                          minDegree = 10, 
                          k.max = 8, 
                          stemming = FALSE, 
                          labelsize = 8,
                          documents = 20)
```


#### Thematic Map

Co-word analysis draws clusters of keywords. They are considered as themes, whose density and centrality can be used in classifying themes and mapping in a two-dimensional diagram.

Thematic map is a very intuitive plot and we can analyze themes according to the quadrant in which they are placed: (1) upper-right quadrant: motor-themes; (2) lower-right quadrant: basic themes; (3) lower-left quadrant: emerging or disappearing themes; (4) upper-left quadrant: very specialized/niche themes.

Please see Cobo, M. J., López-Herrera, A. G., Herrera-Viedma, E., & Herrera, F. (2011). An approach for detecting, quantifying, and visualizing the evolution of a research field: A practical application to the fuzzy sets theory field. Journal of Informetrics, 5(1), 146-166.

```{r Keyword Network, fig.height15, fig.width=15}
NetMatrix <- biblioNetwork(M, 
                           analysis = "co-occurrences",
                           network = "keywords", 
                           sep = ";")

S <- normalizeSimilarity(NetMatrix, 
                         type = "association")

net <- networkPlot(S,
                   n = 500, 
                   Title = "Keyword co-occurrences",
                   type = "fruchterman",
                   labelsize = 2, 
                   halo = FALSE,
                   cluster = "walktrap", 
                   remove.isolates = FALSE,
                   remove.multiple = FALSE, 
                   noloops = TRUE, 
                   weighted = TRUE,
                   label.cex = TRUE,
                   edgesize = 5, 
                   size = 1,
                   edges.min = 2)
```


```{r ThematicMap, fig.height15, fig.width=15}
Map <- thematicMap(M,
                   minfreq =5 )
plot(Map$map)
```

Lets inspect the clusters we found:

```{r}
clusters <-Map$words %>%
  arrange(Cluster, desc(Occurrences))

clusters %>%
  select(Cluster, Words, Occurrences) %>%
  group_by(Cluster) %>%
  mutate(n.rel = Occurrences / sum(Occurrences) ) %>%
  slice(1:3)
```



### The social structure - Collaboration Analysis

Collaboration networks show how authors, institutions (e.g. universities or departments) and countries relate to others in a specific field of research. For example, the first figure below is a co-author network. It discovers regular study groups, hidden groups of scholars, and pivotal authors. The second figure is called "Edu collaboration network" and uncovers relevant institutions in a specific research field and their relations.

#### Author collaboration network
```{r, Au collaboration network, fig.height=15, fig.width=15}
NetMatrix <- biblioNetwork(M %>% filter(!grepl("GESCHWIND", AU)), 
                           analysis = "collaboration",  
                           network = "authors", 
                           sep = ";")

S <- normalizeSimilarity(NetMatrix, type = "jaccard")

net <- networkPlot(S,  
                   n = 50, 
                   Title = "Author collaboration",
                   type = "auto", 
                   size = 10,
                   weighted = TRUE,
                   remove.isolates = TRUE,
                   size.cex = TRUE,
                   edgesize = 1,
                   labelsize = 0.6)
```


#### Edu collaboration network

```{r, Edu collaboration network, fig.height=10, fig.width=10}
NetMatrix <- biblioNetwork(M, 
                           analysis = "collaboration",  
                           network = "universities", 
                           sep = ";")

net <- networkPlot(NetMatrix,  
                   n = 50, 
                   Title = "Edu collaboration",
                   type = "auto", 
                   size = 10,
                   size.cex = T,
                   edgesize = 3,
                   labelsize = 0.6)
```



#### Country collaboration network

```{r, Co collaboration network, fig.height=15, fig.width=15}
M <- metaTagExtraction(M, 
                       Field = "AU_CO", 
                       sep = ";")

NetMatrix <- biblioNetwork(M, 
                           analysis = "collaboration",  
                           network = "countries", 
                           sep = ";")

net <- networkPlot(NetMatrix,  
                   n = dim(NetMatrix)[1], 
                   Title = "Country collaboration",
                   type = "sphere", 
                   cluster = "lovain",
                   weighted = TRUE,
                   size = 10,
                   size.cex = T,
                   edgesize = 1,
                   labelsize = 0.6)
```

Isn't that all a lot of fun? 

By now you should have realized that different leevel of projection and aggregation offer almost endless possibilities for analysis of ibliographic data!

By the way: We can also do all of that with `tidygraph` and `ggraph`

```{r}
g <- NetMatrix %>% as.matrix() %>% as_tbl_graph(directed = FALSE)
g
```

```{r}
g <- g %N>%
    mutate(community = as.factor(group_louvain(weights = weight))) 
```


```{r}
g %N>%
  mutate(dgr = centrality_degree(weights = weight)) %>%
  arrange(desc(dgr)) %>%
  slice(1:200) %>%
  ggraph(layout = 'fr') + 
  geom_edge_link(aes(width = weight), alpha = 0.2, colour = "grey") + 
  geom_node_point(aes(colour = community, size = dgr)) + 
  geom_node_text(aes(label = name), size = 1, repel = FALSE) +
  theme_graph()
```


